{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ad732d-3c23-4bf6-9458-c7bb34c35245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet18\n",
    "from copy import deepcopy\n",
    "import torch.nn.functional as F\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running on device:\", DEVICE.upper())\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "# manual random seed is used for dataset partitioning\n",
    "# to ensure reproducible results across runs\n",
    "RNG = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453fce9b-0b5c-47c5-881b-b7576d9fcca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./Alzheimer_data/\"\n",
    "root_dir = \"./\"\n",
    "test_dir = base_dir + \"test/\"\n",
    "train_dir = base_dir + \"train/\"\n",
    "work_dir = root_dir + \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235b2c3b-429f-457b-a5f4-05fc4f91cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [ 'NonDemented',\n",
    "            'VeryMildDemented',\n",
    "            'MildDemented',\n",
    "            'ModerateDemented']\n",
    "\n",
    "ZOOM = [0.99, 1.01]\n",
    "BRIGHT_RANGE = [0.8, 1.2]\n",
    "HORZ_FLIP = True\n",
    "FILL_MODE = \"constant\"\n",
    "DATA_FORMAT = \"channels_last\"\n",
    "DIM = (224, 224)  # Replace with your desired target size\n",
    "BATCH_SIZE = 32  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50479d37-dbe0-4597-844e-e1f54685f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Assuming you have predefined values for DIM, HORZ_FLIP, ZOOM, BRIGHT_RANGE, BATCH_SIZE, and train_dir\n",
    "\n",
    "# PyTorch transforms equivalent to Keras ImageDataGenerator\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(DIM),\n",
    "    transforms.RandomHorizontalFlip(p=0.5) if HORZ_FLIP else transforms.RandomHorizontalFlip(p=0),\n",
    "    transforms.RandomAffine(degrees=0, scale=ZOOM, shear=0),\n",
    "    transforms.ColorJitter(brightness=BRIGHT_RANGE, contrast=(1, 1), saturation=(1, 1), hue=0),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomImageFolderDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.image_folder = ImageFolder(root, transform)\n",
    "        self.num_classes = len(self.image_folder.classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.image_folder[idx]\n",
    "\n",
    "        # Convert label to one-hot vector\n",
    "        one_hot_label = torch.zeros(self.num_classes)\n",
    "        one_hot_label[label] = 1.0\n",
    "\n",
    "        return img, one_hot_label\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = CustomImageFolderDataset(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc06b252-69aa-423a-b076-dfde487480df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d8df3dc-ed8f-465a-8a28-d5ee49707029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dbc5ccd-9e52-4637-99be-e9bdbf5d9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageFolderDataset(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3032272-1f0b-4ebc-a060-4df0021ecdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ranka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "model_pytorch = models.resnet18(pretrained=True)\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "num_ftrs = model_pytorch.fc.in_features\n",
    "model_pytorch.fc = nn.Linear(num_ftrs, 4)  # Assuming 4 output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e533226-9ae9-449d-acb2-e2e849faa92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e51e0d-0cc0-47a7-9a98-42697b09606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch  0\n",
      "Epoch [1/10], Loss: 0.6748, Training Accuracy: 59.60%\n",
      "Running epoch  1\n",
      "Epoch [2/10], Loss: 0.7597, Training Accuracy: 75.96%\n",
      "Running epoch  2\n",
      "Epoch [3/10], Loss: 1.0584, Training Accuracy: 85.74%\n",
      "Running epoch  3\n",
      "Epoch [4/10], Loss: 0.2967, Training Accuracy: 93.05%\n",
      "Running epoch  4\n",
      "Epoch [5/10], Loss: 1.0428, Training Accuracy: 96.82%\n",
      "Running epoch  5\n",
      "Epoch [6/10], Loss: 4.0739, Training Accuracy: 97.48%\n",
      "Running epoch  6\n",
      "Epoch [7/10], Loss: 0.8348, Training Accuracy: 97.95%\n",
      "Running epoch  7\n",
      "Epoch [8/10], Loss: 0.3699, Training Accuracy: 98.89%\n",
      "Running epoch  8\n",
      "Epoch [9/10], Loss: 0.4108, Training Accuracy: 99.12%\n",
      "Running epoch  9\n",
      "Epoch [10/10], Loss: 0.4352, Training Accuracy: 98.89%\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification problems\n",
    "optimizer = torch.optim.SGD(model_pytorch.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_pytorch.to(device)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Running epoch \", epoch)\n",
    "\n",
    "    # Variables to track training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_pytorch(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "    # Calculate training accuracy and print it\n",
    "    training_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Training Accuracy: {100 * training_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd8b382-96d7-46a1-8814-163b659967d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_pytorch.state_dict(), 'origional_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d42a86-86b2-46be-a8c0-05dc768b5737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.63%\n"
     ]
    }
   ],
   "source": [
    "model_pytorch.eval()\n",
    "\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_pytorch(inputs)\n",
    "\n",
    "        # Track test accuracy\n",
    "        _, predicted_test = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted_test == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = correct_test / total_test\n",
    "print(f'Test Accuracy: {100 * test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bba1d71-58c8-43fe-afd0-722d9b46c30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a788cf6-6d99-44ca-bef0-8c8f226b26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_model_pytorch = models.resnet18(pretrained=True)\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "num_ftrs = rt_model_pytorch.fc.in_features\n",
    "rt_model_pytorch.fc = nn.Linear(num_ftrs, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60aabcda-7bdf-4140-9c42-0565296fb5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_model_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7784d27a-0985-44e9-a108-7ff20fafa058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices in forget_loader: [2287, 2572, 3384, 494, 3545, 4957, 2293, 827, 149, 2165, 4422, 1257, 633, 4789, 4882, 2900, 1429, 3049, 4100, 2588, 2801, 1684, 1551, 3113, 4824, 1196, 4854, 145, 2068, 1167, 1191, 3690, 962, 708, 4324, 258, 543, 1178, 4891, 421, 2778, 37, 2108, 4190, 1766, 2703, 259, 801, 1924, 4463, 3118, 2642, 3562, 3809, 1559, 570, 386, 4284, 0, 186, 1567, 5085, 397, 2931, 2853, 215, 1630, 2975, 4312, 2887, 2008, 4944, 4079, 2747, 802, 3091, 3974, 974, 4144, 3536, 3665, 70, 368, 5080, 1562, 4269, 2081, 2787, 724, 1401, 2732, 4906, 3950, 2936, 830, 992, 5086, 3793, 3022, 4414, 595, 1201, 884, 1962, 1995, 182, 2023, 3651, 1344, 2080, 3997, 717, 1198, 5036, 2211, 3940, 382, 1856, 1041, 5011, 4083, 562, 2539, 1336, 3906, 563, 3995, 4632, 4365, 2847, 157, 3838, 2623, 3938, 4169, 4268, 3799, 1174, 805, 3892, 220, 625, 970, 3175, 4137, 1086, 117, 385, 2278, 4069, 5066, 3466, 457, 3493, 2209, 671, 2630, 4478, 4255, 2004, 780, 1938, 713, 2345, 4628, 4822, 3356, 2138, 1734, 3413, 1898, 3823, 4211, 2462, 2249, 1313, 4030, 6, 2303, 2253, 2485, 2639, 3144, 4166, 612, 1877, 1357, 3209, 2763, 4792, 1507, 1640, 3796, 4311, 630, 813, 1557, 214, 672, 2160, 387, 597, 379, 192, 3301, 548, 833, 2930, 938, 1834, 3243, 1236, 4429, 565, 486, 1100, 4174, 3917, 287, 2013, 2742, 1098, 359, 1658, 3063, 1360, 2228, 1115, 3488, 1737, 1278, 4798, 284, 3244, 4023, 2809, 2984, 82, 4843, 2776, 4858, 3421, 2551, 2831, 585, 4172, 2450, 393, 4377, 666, 1700, 3754, 425, 911, 1145, 854, 479, 2957, 4280, 1552, 603, 4275, 3275, 1925, 2978, 3594, 3667, 4315, 3723, 4667, 1509, 2910, 4570, 945, 4131, 3878, 163, 2686, 3071, 3881, 3185, 4102, 4175, 231, 3899, 2275, 719, 817, 197, 951, 4349, 954, 1487, 893, 2757, 2009, 1778, 2134, 2881, 292, 3650, 2427, 4670, 1272, 3248, 1031, 2408, 4784, 62, 1341, 468, 4541, 948, 4387, 525, 4505, 272, 4525, 3792, 4623, 1265, 107, 2805, 4660, 460, 2516, 4625, 3498, 458, 4160, 3430, 4940, 2150, 4254, 283, 2739, 4078, 1523, 3830, 22, 3542, 2750, 3104, 1173, 3976, 4325, 2476, 1416, 483, 4179, 3334, 1780, 3619, 3073, 4076, 2489, 2654, 4223, 1638, 188, 3445, 2090, 3240, 834, 4536, 656, 1168, 4415, 4637, 4065, 1935, 3814, 461, 2028, 2633, 4982, 2086, 175, 1409, 4056, 1140, 2246, 2717, 4203, 1454, 4304, 4456, 3675, 19, 3217, 4313, 4360, 2879, 1147, 4608, 3759, 156, 3931, 2533, 1860, 1868, 3592, 4068, 340, 2579, 2234, 3364, 4779, 2044, 2400, 1169, 3390, 3394, 3298, 1057, 2071, 4207, 227, 2933, 2283, 4697, 1441, 4239, 2997, 3166, 3331, 3708, 1484, 3989, 943, 1324, 981, 4500, 3911, 2263, 3853, 1204, 1494, 1325, 5098, 3053, 4015, 3457, 977, 3865, 2498, 1599, 1240, 4384, 1878, 5061, 3385, 2609, 2891, 135, 4941, 2282, 955, 1852, 52, 4234, 4567, 2593, 816, 734, 1831, 4813, 4388, 828, 250, 130, 332, 1135, 1488, 3154, 229, 4752, 2070, 466, 2413, 3753, 3520, 3533, 4863, 4848, 1259, 3051, 2077, 2983, 3854, 4656, 3960, 3978, 3417, 20, 2268, 3414, 1264, 1334, 4776, 4785, 4749, 5088, 1541, 4495, 4549, 508, 4396, 1353, 3045, 4090, 4470, 522, 4832, 2708, 3280, 1110, 1053, 5067, 1980, 3361, 1581, 63, 1609, 4929, 4018, 2301, 343, 3905, 4607, 1624, 749, 3444, 2124, 542, 3710, 3836, 3342, 1371, 3928, 2310, 3004, 3571, 4224, 3341, 3845, 1957, 3828, 277, 527, 1232, 1477, 1753, 4171, 2622, 959, 4852, 2348, 1703, 1252, 2040, 3033, 3393, 1947, 4936, 4539, 763, 5044, 5104, 1022, 2926, 5075, 438, 1715, 554, 4165, 2313, 742, 3090, 4410, 2011, 3647, 392, 2507, 162, 111, 611, 1446, 3410, 4920, 1817, 4431, 4228, 2456, 4583, 3458, 1952, 3684, 4715, 3716, 2735, 2468, 3318, 1869, 4133, 2774, 330, 915, 2457, 1020, 4437, 2767, 521, 3603, 5034, 1083, 2003, 874, 29, 1960, 4550, 2131, 64, 2356, 80, 4573, 4978, 2748, 1999, 3089, 3329, 1862, 2362, 2878, 2015, 4040, 1722, 2329, 244, 2564, 4544, 2897, 1500, 3352, 3891, 3312, 314, 1032, 1158, 3099, 3258, 3926, 3230, 3272, 4184, 2404, 518, 2126, 4989, 1458, 4921, 1782, 2487, 3168, 2917, 3727, 3375, 1437, 4885, 3966, 4436, 4391, 1761, 194, 1710, 1767, 3631, 3247, 4099, 4786, 659, 3760, 2431, 1913, 1690, 3915, 1900, 3422, 2548, 650, 3947, 1123, 2472, 3238, 768, 1082, 4841, 4257, 1309, 1954, 1918, 4864, 2358, 2855, 1770, 4468, 1013, 1253, 3771, 2232, 2892, 3841, 568, 4502, 1743, 881, 821, 410, 986, 4352, 3994, 3347, 2198, 3287, 2302, 710, 2700, 4014, 3934, 3415, 1068, 3738, 2079, 740, 972, 628, 751, 995, 1156, 245, 2050, 773, 3748, 4569, 652, 1175, 3585, 4001, 1968, 730, 3483, 2280, 3930, 4503, 5060, 4004, 4814, 1039, 3999, 252, 295, 3218, 747, 1812, 2839, 3689, 4297, 4933, 1369, 4215, 2141, 2363, 3887, 2795, 3017, 96, 4874, 2204, 4851, 3975, 519, 266, 1731, 1585, 275, 451, 1589, 2996, 2458, 4872, 497, 3531, 2164, 3284, 5026, 2059, 2640, 153, 946, 3192, 788, 3698, 5102, 3918, 87, 1010, 11, 1408, 692, 2568, 2987, 302, 3277, 1727, 4911, 757, 2055, 3135, 614, 2244, 4012, 3207, 308, 3219, 3255, 3431, 4301, 575, 1976, 5111, 3986, 937, 2895, 4672, 1091, 2132, 2866, 2923, 4930, 3291, 1193, 2380, 3613, 2541, 3850, 4411, 1499, 2399, 2883, 1922, 2753, 836, 3507, 1314, 238, 4357, 883, 1698, 2064, 4833, 339, 3074, 3977, 4181, 4935, 49, 21, 1983, 198, 4702, 17, 2599, 89, 3282, 594, 334, 1485, 1832, 147, 4290, 2573, 1439, 5065, 4700, 2036, 2728, 3617, 4556, 2657, 44, 1445, 4771, 3084, 1465, 2681, 3942, 2527, 5004, 1870, 1861, 4514, 2525, 2273, 2065, 2237, 1045, 1592, 1536, 1911, 2610, 4617, 3959, 845, 5005, 4523, 4025, 1215, 4913, 4273, 1434, 551, 4754, 4085, 513, 394, 3550, 3141, 2439, 5077, 1370, 545, 3591, 3127, 2083, 1985, 2323, 4081, 4823, 4392, 609, 3540, 5033, 3532, 3416, 3221, 4321, 1163, 4017, 3478, 3979, 3259, 2559, 290, 4856, 2167, 323, 5119, 3625, 2192, 4602, 3290, 459, 1891, 738, 4361, 1181, 213, 4581, 4477, 4310, 1291, 1736, 787, 3778, 766, 4571, 3884, 3304, 2558, 856, 3271, 4053, 3400, 3214, 4449, 3107, 4363, 2387, 429, 5022, 2343, 1586, 3895, 1217, 892, 1222, 2816, 2938, 1225, 1030, 634, 1646, 4364, 2102, 129, 1380, 1317, 4938, 3447, 1665, 416, 673, 383, 4646, 4575, 1142, 877, 2698, 2790, 663, 204, 412, 3673, 1506, 2958]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Assuming you have a dataset named 'train_dataset' and BATCH_SIZE defined\n",
    "\n",
    "# Calculate the sizes for retain and forget loaders\n",
    "retain_size = int(0.8 * len(train_dataset))  # 80% for retain_loader\n",
    "forget_size = len(train_dataset) - retain_size  # 20% for forget_loader\n",
    "\n",
    "# Split the dataset into retain and forget using random_split\n",
    "retain_dataset, forget_dataset = random_split(train_dataset, [retain_size, forget_size])\n",
    "\n",
    "# Create DataLoader instances for retain and forget\n",
    "retain_loader = DataLoader(retain_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# Get the indices of the samples in forget_loader\n",
    "forget_indices = list(forget_dataset.indices)\n",
    "\n",
    "# Print the indices for verification\n",
    "print(\"Indices in forget_loader:\", forget_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29a426fe-a1cd-4402-8cb5-f09ca0905aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forget_indices.txt', 'w') as file:\n",
    "    for index in forget_indices:\n",
    "        file.write(f\"{index}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72a2c8b-54b5-4458-b5dd-c2196959302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forget_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3a66c78-648f-4bd8-9980-d895c36d768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retain_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c21daf1-bfc3-418d-96df-87b2d96f7047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5121"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e249e6df-0e10-42f0-915c-a2ee6a1f94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch  0\n",
      "Epoch [1/10], Loss: 1.3656, Training Accuracy: 27.25%\n",
      "Running epoch  1\n",
      "Epoch [2/10], Loss: 1.4694, Training Accuracy: 25.90%\n",
      "Running epoch  2\n",
      "Epoch [3/10], Loss: 1.4194, Training Accuracy: 25.95%\n",
      "Running epoch  3\n",
      "Epoch [4/10], Loss: 1.3694, Training Accuracy: 25.07%\n",
      "Running epoch  4\n",
      "Epoch [5/10], Loss: 1.4712, Training Accuracy: 26.12%\n",
      "Running epoch  5\n",
      "Epoch [6/10], Loss: 1.4628, Training Accuracy: 26.25%\n",
      "Running epoch  6\n",
      "Epoch [7/10], Loss: 1.3692, Training Accuracy: 24.90%\n",
      "Running epoch  7\n",
      "Epoch [8/10], Loss: 1.3773, Training Accuracy: 27.32%\n",
      "Running epoch  8\n",
      "Epoch [9/10], Loss: 1.3866, Training Accuracy: 26.32%\n",
      "Running epoch  9\n",
      "Epoch [10/10], Loss: 1.4128, Training Accuracy: 25.88%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Running epoch \", epoch)\n",
    "\n",
    "    # Variables to track training accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in retain_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = rt_model_pytorch(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "    # Calculate training accuracy and print it\n",
    "    training_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Training Accuracy: {100 * training_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7428e48-0daf-4b88-a9e8-96938f156527",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rt_model_pytorch.state_dict(), 'retrain_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd85e2-a5f1-4d19-969f-509fb9a0fa9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
