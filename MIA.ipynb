{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Qq0kVZHDxZX"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scikit-like estimators for the attack model and shadow models.\n",
    "\"\"\"\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class ShadowModelBundle(sklearn.base.BaseEstimator):\n",
    "    \"\"\"\n",
    "    A bundle of shadow models.\n",
    "\n",
    "    :param model_fn: Function that builds a new shadow model\n",
    "    :param shadow_dataset_size: Size of the training data for each shadow model\n",
    "    :param num_models: Number of shadow models\n",
    "    :param seed: Random seed\n",
    "    :param ModelSerializer serializer: Serializer for the models. If None,\n",
    "            the shadow models will be stored in memory. Otherwise, loaded\n",
    "            and saved when needed.\n",
    "    \"\"\"\n",
    "\n",
    "    MODEL_ID_FMT = \"shadow_%d\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model_fn, shadow_dataset_size, num_models=20, seed=42, serializer=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_fn = model_fn\n",
    "        self.shadow_dataset_size = shadow_dataset_size\n",
    "        self.num_models = num_models\n",
    "        self.seed = seed\n",
    "        self.serializer = serializer\n",
    "        self._reset_random_state()\n",
    "\n",
    "    def fit_transform(self, X, y, verbose=False, fit_kwargs=None):\n",
    "        \"\"\"Train the shadow models and get a dataset for training the attack.\n",
    "\n",
    "        :param X: Data coming from the same distribution as the target\n",
    "                  training data\n",
    "        :param y: Data labels\n",
    "        :param bool verbose: Whether to display the progressbar\n",
    "        :param dict fit_kwargs: Arguments that will be passed to the fit call for\n",
    "                each shadow model.\n",
    "\n",
    "        .. note::\n",
    "            Be careful when holding out some of the passed data for validation\n",
    "            (e.g., if using Keras, passing `fit_kwargs=dict(validation_split=0.7)`).\n",
    "            Such data will be marked as \"used in training\", whereas it was used for\n",
    "            validation. Doing so may decrease the success of the attack.\n",
    "        \"\"\"\n",
    "        self._fit(X, y, verbose=verbose, fit_kwargs=fit_kwargs)\n",
    "        return self._transform(verbose=verbose)\n",
    "\n",
    "    def _reset_random_state(self):\n",
    "        self._prng = np.random.RandomState(self.seed)\n",
    "\n",
    "    def _get_model_iterator(self, indices=None, verbose=False):\n",
    "        if indices is None:\n",
    "            indices = range(self.num_models)\n",
    "        if verbose:\n",
    "            indices = tqdm(indices)\n",
    "        return indices\n",
    "\n",
    "    def _get_model(self, model_index):\n",
    "        if self.serializer is not None:\n",
    "            model_id = ShadowModelBundle.MODEL_ID_FMT % model_index\n",
    "            model = self.serializer.load(model_id)\n",
    "        else:\n",
    "            model = self.shadow_models_[model_index]\n",
    "        return model\n",
    "\n",
    "    def _fit(self, X, y, verbose=False, pseudo=False, fit_kwargs=None):\n",
    "        \"\"\"Train the shadow models.\n",
    "\n",
    "        .. note::\n",
    "        Be careful not to hold out some of the passed data for validation\n",
    "        (e.g., if using Keras, passing `fit_kwargs=dict(validation_split=0.7)`).\n",
    "        Such data will be incorrectly marked as \"used in training\", whereas\n",
    "        it was not.\n",
    "\n",
    "        :param X: Data coming from the same distribution as the target\n",
    "                  training data\n",
    "        :param y: Data labels\n",
    "        :param bool verbose: Whether to display the progressbar\n",
    "        :param bool pseudo: If True, does not fit the models\n",
    "        :param dict fit_kwargs: Arguments that will be passed to the fit call for\n",
    "                each shadow model.\n",
    "        \"\"\"\n",
    "        self.shadow_train_indices_ = []\n",
    "        self.shadow_test_indices_ = []\n",
    "\n",
    "        if self.serializer is None:\n",
    "            self.shadow_models_ = []\n",
    "\n",
    "        fit_kwargs = fit_kwargs or {}\n",
    "        indices = np.arange(X.shape[0])\n",
    "\n",
    "        for i in self._get_model_iterator(verbose=verbose):\n",
    "            # Pick indices for this shadow model.\n",
    "            shadow_indices = self._prng.choice(\n",
    "                indices, 2 * self.shadow_dataset_size, replace=False\n",
    "            )\n",
    "            train_indices = shadow_indices[: self.shadow_dataset_size]\n",
    "            test_indices = shadow_indices[self.shadow_dataset_size :]\n",
    "            X_train, y_train = X[train_indices], y[train_indices]\n",
    "            self.shadow_train_indices_.append(train_indices)\n",
    "            self.shadow_test_indices_.append(test_indices)\n",
    "\n",
    "            if pseudo:\n",
    "                continue\n",
    "\n",
    "            # Train the shadow model.\n",
    "            shadow_model = self.model_fn()\n",
    "            shadow_model.fit(X_train, y_train, **fit_kwargs)\n",
    "            if self.serializer is not None:\n",
    "                self.serializer.save(ShadowModelBundle.MODEL_ID_FMT % i, shadow_model)\n",
    "            else:\n",
    "                self.shadow_models_.append(shadow_model)\n",
    "\n",
    "        self.X_fit_ = X\n",
    "        self.y_fit_ = y\n",
    "        self._reset_random_state()\n",
    "        return self\n",
    "\n",
    "    def _pseudo_fit(self, X, y, verbose=False, fit_kwargs=None):\n",
    "        self._fit(X, y, verbose=verbose, fit_kwargs=fit_kwargs, pseudo=True)\n",
    "\n",
    "    def _transform(self, shadow_indices=None, verbose=False):\n",
    "        \"\"\"Produce in/out data for training the attack model.\n",
    "\n",
    "        :param shadow_indices: Indices of the shadow models to use\n",
    "                for generating output data.\n",
    "        :param verbose: Whether to show progress\n",
    "        \"\"\"\n",
    "        shadow_data_array = []\n",
    "        shadow_label_array = []\n",
    "\n",
    "        model_index_iter = self._get_model_iterator(\n",
    "            indices=shadow_indices, verbose=verbose\n",
    "        )\n",
    "\n",
    "        for i in model_index_iter:\n",
    "            shadow_model = self._get_model(i)\n",
    "            train_indices = self.shadow_train_indices_[i]\n",
    "            test_indices = self.shadow_test_indices_[i]\n",
    "\n",
    "            train_data = self.X_fit_[train_indices], self.y_fit_[train_indices]\n",
    "            test_data = self.X_fit_[test_indices], self.y_fit_[test_indices]\n",
    "            shadow_data, shadow_labels = prepare_attack_data(\n",
    "                shadow_model, train_data, test_data\n",
    "            )\n",
    "\n",
    "            shadow_data_array.append(shadow_data)\n",
    "            shadow_label_array.append(shadow_labels)\n",
    "\n",
    "        X_transformed = np.vstack(shadow_data_array).astype(\"float32\")\n",
    "        y_transformed = np.hstack(shadow_label_array).astype(\"float32\")\n",
    "        return X_transformed, y_transformed\n",
    "\n",
    "\n",
    "def prepare_attack_data(model, data_in, data_out):\n",
    "    \"\"\"\n",
    "    Prepare the data in the attack model format.\n",
    "\n",
    "    :param model: Classifier\n",
    "    :param (X, y) data_in: Data used for training\n",
    "    :param (X, y) data_out: Data not used for training\n",
    "\n",
    "    :returns: (X, y) for the attack classifier\n",
    "    \"\"\"\n",
    "    X_in, y_in = data_in\n",
    "    X_out, y_out = data_out\n",
    "\n",
    "    #y_hat_in = model.predict_proba(X_in)\n",
    "    y_hat_in = model.predict(X_in)\n",
    "\n",
    "    #y_hat_out = model.predict_proba(X_out)\n",
    "    y_hat_out = model.predict(X_out)\n",
    "\n",
    "    labels = np.ones(y_in.shape[0])\n",
    "    labels = np.hstack([labels, np.zeros(y_out.shape[0])])\n",
    "    # TODO: this does not work for non-one-hot labels.\n",
    "    # data = np.hstack([y_hat_in, y_in])\n",
    "    data = np.c_[y_hat_in, y_in]\n",
    "    data = np.vstack([data, np.c_[y_hat_out, y_out]])\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "class AttackModelBundle(sklearn.base.BaseEstimator):\n",
    "    \"\"\"\n",
    "    A bundle of attack models, one for each target model class.\n",
    "\n",
    "    :param model_fn: Function that builds a new shadow model\n",
    "    :param num_classes: Number of classes\n",
    "    :param ModelSerializer serializer: Serializer for the models. If not None,\n",
    "            the models will not be stored in memory, but rather loaded\n",
    "            and saved when needed.\n",
    "    :param class_one_hot_encoded: Whether the shadow data uses one-hot encoded\n",
    "            class labels.\n",
    "    \"\"\"\n",
    "\n",
    "    MODEL_ID_FMT = \"attack_%d\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model_fn, num_classes, serializer=None, class_one_hot_coded=True\n",
    "    ):\n",
    "        self.model_fn = model_fn\n",
    "        self.num_classes = num_classes\n",
    "        self.serializer = serializer\n",
    "        self.class_one_hot_coded = class_one_hot_coded\n",
    "\n",
    "    def fit(self, X, y, verbose=False, fit_kwargs=None):\n",
    "        \"\"\"Train the attack models.\n",
    "\n",
    "        :param X: Shadow predictions coming from\n",
    "                  :py:func:`ShadowBundle.fit_transform`.\n",
    "        :param y: Ditto\n",
    "        :param verbose: Whether to display the progressbar\n",
    "        :param fit_kwargs: Arguments that will be passed to the fit call for\n",
    "                each attack model.\n",
    "        \"\"\"\n",
    "        X_total = X[:, : self.num_classes]\n",
    "        classes = X[:, self.num_classes :]\n",
    "\n",
    "        datasets_by_class = []\n",
    "        data_indices = np.arange(X_total.shape[0])\n",
    "        for i in range(self.num_classes):\n",
    "            if self.class_one_hot_coded:\n",
    "                class_indices = data_indices[np.argmax(classes, axis=1) == i]\n",
    "            else:\n",
    "                class_indices = data_indices[np.squeeze(classes) == i]\n",
    "\n",
    "            datasets_by_class.append((X_total[class_indices], y[class_indices]))\n",
    "\n",
    "        if self.serializer is None:\n",
    "            self.attack_models_ = []\n",
    "\n",
    "        dataset_iter = datasets_by_class\n",
    "        if verbose:\n",
    "            dataset_iter = tqdm(dataset_iter)\n",
    "        for i, (X_train, y_train) in enumerate(dataset_iter):\n",
    "            model = self.model_fn\n",
    "            fit_kwargs = fit_kwargs or {}\n",
    "            model.fit(X_train, y_train, **fit_kwargs)\n",
    "\n",
    "            if self.serializer is not None:\n",
    "                model_id = AttackModelBundle.MODEL_ID_FMT % i\n",
    "                self.serializer.save(model_id, model)\n",
    "            else:\n",
    "                self.attack_models_.append(model)\n",
    "\n",
    "    def _get_model(self, model_index):\n",
    "        if self.serializer is not None:\n",
    "            model_id = AttackModelBundle.MODEL_ID_FMT % model_index\n",
    "            model = self.serializer.load(model_id)\n",
    "        else:\n",
    "            model = self.attack_models_[model_index]\n",
    "        return model\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        result = np.zeros((X.shape[0], 2))\n",
    "        shadow_preds = X[:, : self.num_classes]\n",
    "        classes = X[:, self.num_classes :]\n",
    "\n",
    "        data_indices = np.arange(shadow_preds.shape[0])\n",
    "        for i in range(self.num_classes):\n",
    "            model = self._get_model(i)\n",
    "            if self.class_one_hot_coded:\n",
    "                class_indices = data_indices[np.argmax(classes, axis=1) == i]\n",
    "            else:\n",
    "                class_indices = data_indices[np.squeeze(classes) == i]\n",
    "\n",
    "            membership_preds = model.predict(shadow_preds[class_indices])\n",
    "            for j, example_index in enumerate(class_indices):\n",
    "                prob = np.squeeze(membership_preds[j])\n",
    "                result[example_index, 1] = prob\n",
    "                result[example_index, 0] = 1 - prob\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)[:, 1]\n",
    "        return probs > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT7XB0aXqZDj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import relu, sigmoid\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3tQE82FfrCdN",
    "outputId": "d59c7d5a-3418-4c20-cc32-380b3cee1dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4PI3t2rsQZg"
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUHmBxUwsPJA"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_test = y_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLG4Wr71_lsq"
   },
   "outputs": [],
   "source": [
    "def target_model_fn():\n",
    "  model = Sequential([\n",
    "      Conv2D(32, (3,3), activation = 'relu', padding = \"same\", input_shape=(32, 32, 3)),\n",
    "      Conv2D(32, (3, 3), activation = 'relu'),\n",
    "      MaxPooling2D((2, 2)),\n",
    "      Dropout(0.25),\n",
    "\n",
    "      Conv2D(64, (3, 3), activation = 'relu', padding='same'),\n",
    "      Conv2D(64, (3, 3), activation = 'relu'),\n",
    "      MaxPooling2D((2, 2)),\n",
    "      Dropout(0.25),\n",
    "\n",
    "      Flatten(),\n",
    "\n",
    "      Dense(512, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(Adam(), loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlmPtFUSsqhB"
   },
   "outputs": [],
   "source": [
    "def attack_models():\n",
    "  nn_model = Sequential([\n",
    "      Dense(128, activation = relu, input_shape=(10,)),\n",
    "      Dropout(0.3, noise_shape=None, seed=None),\n",
    "      Dense(64, activation=relu),\n",
    "      Dropout(0.2, noise_shape=None, seed=None),\n",
    "      Dense(64, activation=relu),\n",
    "      Dense(1, activation=sigmoid)\n",
    "  ])\n",
    "\n",
    "  nn_model.compile(optimizer = Adam(), loss = binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "  random_forest = RandomForestClassifier()\n",
    "  logistic_regression = LogisticRegression()\n",
    "\n",
    "  return [nn_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rq86kFXfw8E2"
   },
   "outputs": [],
   "source": [
    "target_model = target_model_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoMyMk0bFbmu",
    "outputId": "11a32b29-99d7-4b69-d4a4-0aa1f257dee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 - 172s - loss: 1.3105 - accuracy: 0.5303 - val_loss: 1.1302 - val_accuracy: 0.6024 - 172s/epoch - 157ms/step\n",
      "Epoch 2/20\n",
      "1094/1094 - 170s - loss: 1.1051 - accuracy: 0.6053 - val_loss: 0.9781 - val_accuracy: 0.6526 - 170s/epoch - 155ms/step\n",
      "Epoch 3/20\n",
      "1094/1094 - 170s - loss: 0.9848 - accuracy: 0.6509 - val_loss: 0.8874 - val_accuracy: 0.6849 - 170s/epoch - 155ms/step\n",
      "Epoch 4/20\n",
      "1094/1094 - 172s - loss: 0.9020 - accuracy: 0.6840 - val_loss: 0.8041 - val_accuracy: 0.7197 - 172s/epoch - 157ms/step\n",
      "Epoch 5/20\n",
      "1094/1094 - 168s - loss: 0.8340 - accuracy: 0.7061 - val_loss: 0.7678 - val_accuracy: 0.7340 - 168s/epoch - 154ms/step\n",
      "Epoch 6/20\n",
      "1094/1094 - 174s - loss: 0.7771 - accuracy: 0.7249 - val_loss: 0.7482 - val_accuracy: 0.7393 - 174s/epoch - 159ms/step\n",
      "Epoch 7/20\n",
      "1094/1094 - 175s - loss: 0.7307 - accuracy: 0.7439 - val_loss: 0.7479 - val_accuracy: 0.7443 - 175s/epoch - 160ms/step\n",
      "Epoch 8/20\n",
      "1094/1094 - 169s - loss: 0.7017 - accuracy: 0.7550 - val_loss: 0.7148 - val_accuracy: 0.7527 - 169s/epoch - 155ms/step\n",
      "Epoch 9/20\n",
      "1094/1094 - 170s - loss: 0.6629 - accuracy: 0.7669 - val_loss: 0.7384 - val_accuracy: 0.7485 - 170s/epoch - 155ms/step\n",
      "Epoch 10/20\n",
      "1094/1094 - 172s - loss: 0.6466 - accuracy: 0.7718 - val_loss: 0.7216 - val_accuracy: 0.7529 - 172s/epoch - 157ms/step\n",
      "Epoch 11/20\n",
      "1094/1094 - 175s - loss: 0.6145 - accuracy: 0.7813 - val_loss: 0.7237 - val_accuracy: 0.7555 - 175s/epoch - 160ms/step\n",
      "Epoch 12/20\n",
      "1094/1094 - 171s - loss: 0.5882 - accuracy: 0.7914 - val_loss: 0.7138 - val_accuracy: 0.7581 - 171s/epoch - 156ms/step\n",
      "Epoch 13/20\n",
      "1094/1094 - 166s - loss: 0.5714 - accuracy: 0.7945 - val_loss: 0.7205 - val_accuracy: 0.7595 - 166s/epoch - 152ms/step\n",
      "Epoch 14/20\n",
      "1094/1094 - 168s - loss: 0.5525 - accuracy: 0.8043 - val_loss: 0.7092 - val_accuracy: 0.7657 - 168s/epoch - 153ms/step\n",
      "Epoch 15/20\n",
      "1094/1094 - 173s - loss: 0.5390 - accuracy: 0.8086 - val_loss: 0.7154 - val_accuracy: 0.7652 - 173s/epoch - 158ms/step\n",
      "Epoch 16/20\n",
      "1094/1094 - 171s - loss: 0.5233 - accuracy: 0.8146 - val_loss: 0.7062 - val_accuracy: 0.7689 - 171s/epoch - 156ms/step\n",
      "Epoch 17/20\n",
      "1094/1094 - 171s - loss: 0.5113 - accuracy: 0.8194 - val_loss: 0.6968 - val_accuracy: 0.7739 - 171s/epoch - 156ms/step\n",
      "Epoch 18/20\n",
      "1094/1094 - 168s - loss: 0.4967 - accuracy: 0.8237 - val_loss: 0.7166 - val_accuracy: 0.7714 - 168s/epoch - 154ms/step\n",
      "Epoch 19/20\n",
      "1094/1094 - 166s - loss: 0.4905 - accuracy: 0.8249 - val_loss: 0.6971 - val_accuracy: 0.7675 - 166s/epoch - 152ms/step\n",
      "Epoch 20/20\n",
      "1094/1094 - 168s - loss: 0.4792 - accuracy: 0.8320 - val_loss: 0.6970 - val_accuracy: 0.7727 - 168s/epoch - 154ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ffa936b1b40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_model.fit(X_train, y_train, epochs=20, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFcT8c5gECyT"
   },
   "outputs": [],
   "source": [
    "smb = ShadowModelBundle(\n",
    "    target_model_fn,\n",
    "    shadow_dataset_size=3000,\n",
    "    num_models=1,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G4UDfd9vKBt7"
   },
   "outputs": [],
   "source": [
    "X_train_shadow, X_test_shadow, y_train_shadow, y_test_shadow = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.33\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGj6Fsj3LAo1",
    "outputId": "cedf0203-283f-47df-cd6e-72e995497e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 20s 189ms/step - loss: 2.2237 - accuracy: 0.1530 - val_loss: 2.1044 - val_accuracy: 0.2333\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 17s 183ms/step - loss: 1.9880 - accuracy: 0.2740 - val_loss: 1.8389 - val_accuracy: 0.3206\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 18s 192ms/step - loss: 1.7886 - accuracy: 0.3330 - val_loss: 1.7730 - val_accuracy: 0.3833\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 18s 186ms/step - loss: 1.6821 - accuracy: 0.3763 - val_loss: 1.5617 - val_accuracy: 0.4330\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.5087 - accuracy: 0.4460 - val_loss: 1.5203 - val_accuracy: 0.4330\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.4451 - accuracy: 0.4780 - val_loss: 1.4214 - val_accuracy: 0.4848\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.3457 - accuracy: 0.5090 - val_loss: 1.3829 - val_accuracy: 0.4997\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.2457 - accuracy: 0.5577 - val_loss: 1.4312 - val_accuracy: 0.4906\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.2096 - accuracy: 0.5653 - val_loss: 1.3923 - val_accuracy: 0.5064\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.0697 - accuracy: 0.6173 - val_loss: 1.3624 - val_accuracy: 0.5176\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 1.0043 - accuracy: 0.6423 - val_loss: 1.4869 - val_accuracy: 0.5042\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 17s 184ms/step - loss: 0.9624 - accuracy: 0.6523 - val_loss: 1.3888 - val_accuracy: 0.5303\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 18s 195ms/step - loss: 0.8563 - accuracy: 0.6933 - val_loss: 1.4472 - val_accuracy: 0.5182\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 17s 183ms/step - loss: 0.7749 - accuracy: 0.7253 - val_loss: 1.3833 - val_accuracy: 0.5285\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 19s 202ms/step - loss: 0.7084 - accuracy: 0.7487 - val_loss: 1.4681 - val_accuracy: 0.5388\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 17s 183ms/step - loss: 0.6507 - accuracy: 0.7683 - val_loss: 1.4726 - val_accuracy: 0.5315\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 19s 203ms/step - loss: 0.5560 - accuracy: 0.8083 - val_loss: 1.5365 - val_accuracy: 0.5336\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 19s 206ms/step - loss: 0.5221 - accuracy: 0.8140 - val_loss: 1.5614 - val_accuracy: 0.5467\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 17s 181ms/step - loss: 0.4630 - accuracy: 0.8390 - val_loss: 1.6425 - val_accuracy: 0.5458\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 17s 185ms/step - loss: 0.4136 - accuracy: 0.8560 - val_loss: 1.7565 - val_accuracy: 0.5306\n",
      "94/94 [==============================] - 3s 34ms/step\n",
      "94/94 [==============================] - 4s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "X_shadow, y_shadow = smb.fit_transform(\n",
    "    X_train_shadow,\n",
    "    y_train_shadow,\n",
    "    fit_kwargs=dict(\n",
    "        epochs=20,\n",
    "        verbose=True,\n",
    "        validation_data=(X_test_shadow, y_test_shadow),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiKaDIhxWQyL",
    "outputId": "0b040258-bbaf-4d42-a73e-a718229b74f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 1s 3ms/step - loss: 0.6675 - accuracy: 0.6783\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7118\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7309\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7404\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7341\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7404\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7516\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7452\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7404\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7468\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7357\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7500\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7516\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7564\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7484\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7484\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7452\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7468\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7484\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7484\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.8032 - accuracy: 0.5190\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5835\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.6579\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.7025\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7074\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7355\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7124\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7240\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7207\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7240\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7240\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7289\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7223\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7322\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7223\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7306\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7190\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7339\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7322\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.5283\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.5967\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7967\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8217\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8117\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8317\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8167\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8283\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8317\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8383\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8300\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8350\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8267\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8250\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8433\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8383\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8383\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8367\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.4671 - accuracy: 0.4579\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5455\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6331\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7355\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7702\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7802\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7983\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8066\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8099\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8132\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8149\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8116\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8149\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.8132\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8165\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8198\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8248\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8165\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8083\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8198\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.9802 - accuracy: 0.5323\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6820\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7160\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7636\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7534\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7721\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7806\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7908\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7925\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7874\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7891\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7908\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7993\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7993\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7942\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7959\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7925\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7976\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7908\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8095\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.5884\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.6939\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7347\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7483\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7653\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7687\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7772\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7874\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7925\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.8010\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7925\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7925\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7976\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8010\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7874\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7976\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7959\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7908\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9480 - accuracy: 0.5772\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.6265\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6587\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.6876\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.6910\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7063\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.6859\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7080\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7046\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7029\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7080\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7233\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7029\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7063\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7165\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7114\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7080\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.6995\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7114\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7097\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1522 - accuracy: 0.5863\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.6449\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7253\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7152\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7404\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7320\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7370\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7303\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7370\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7471\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7270\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7353\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7404\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7370\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7387\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7387\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7370\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7420\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7437\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3068 - accuracy: 0.5391\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6556\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6805\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6955\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6955\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.6972\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.6805\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7005\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7022\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7038\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7205\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7138\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7188\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7205\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7038\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7072\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7238\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7205\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7171\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7171\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.2332 - accuracy: 0.5509\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7012\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7396\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7479\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7513\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7596\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7830\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7730\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7730\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7763\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7830\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7813\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7863\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7780\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7796\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7813\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7880\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7913\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7880\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7796\n",
      "94/94 [==============================] - 3s 35ms/step\n",
      "94/94 [==============================] - 4s 43ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "Attack accuracy with Sequential is \n",
      "0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "for attack_model in attack_models():\n",
    "  amb = AttackModelBundle(attack_model, num_classes=10)\n",
    "\n",
    "  amb.fit(\n",
    "      X_shadow,\n",
    "      y_shadow,\n",
    "      fit_kwargs=dict(\n",
    "          epochs=20,\n",
    "          verbose=True\n",
    "          )\n",
    "  )\n",
    "\n",
    "  data_in = X_train[:3000], y_train[:3000]\n",
    "  data_out = X_test[:3000], y_test[:3000]\n",
    "\n",
    "  attack_test_data, real_membership_labels = prepare_attack_data(\n",
    "                                                                target_model,\n",
    "                                                                data_in,\n",
    "                                                                data_out\n",
    "                                                              )\n",
    "\n",
    "  attack_guesses = amb.predict(attack_test_data)\n",
    "  attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n",
    "\n",
    "  print(f'Attack accuracy with {attack_model. __class__. __name__} is \\n{attack_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
