{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTLmlhXcBgvI"
   },
   "source": [
    "The problem - Retraining from sctrach is heavy on computational time. The reason behind this is the slow back propagation of the model state using gradient descent on all parameters that are starting from a random state.\n",
    "\n",
    "The approach - Retaining the global information existing on the original model and confusing it's vision to reconstruct it later properly.\n",
    "\n",
    "Custom loss function -\n",
    "\n",
    "$loss = -(1/N) \\displaystyle\\sum_{i=1}^{N} w_i log(p_i)$\n",
    "\n",
    "$p_i - probability\\ related\\ to\\ the\\ i^{th}\\ image$\n",
    "\n",
    "$w_i - weight\\ associated\\ to\\ the\\ target\\ of\\ the\\ i^{th}\\ image$\n",
    "\n",
    "where weights are equally assigned to each class as 0.5 except *'class 0'*, where the weight is 1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QADNxqsY0C1j",
    "outputId": "946f87b0-eaef-44f1-f174-ab80da1326fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKdA-w4MAMT-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svDc6fCRz4Ik",
    "outputId": "570001ce-d468-447c-9051-8fe0b6e4d719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py:157: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(sample)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "(X_train, y_train), held_out = keras.datasets.cifar10.load_data()\n",
    "test_set, val_set = keras.utils.split_dataset(held_out, left_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuSjmCBx0M3C"
   },
   "outputs": [],
   "source": [
    "def normalize(image, label, denorm=False):\n",
    "    rescale = keras.layers.Rescaling(scale=1./255.)\n",
    "    norms = keras.layers.Normalization(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        variance=[np.square(0.2023), np.square(0.1994), np.square(0.2010)],\n",
    "        invert=denorm,\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    if not denorm:\n",
    "        image = rescale(image)\n",
    "    return norms(image), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsE9Id7y0R-y"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_ds = train_ds.map(normalize)\n",
    "train_ds = train_ds.shuffle(buffer_size=8*BATCH_SIZE)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = val_set.map(normalize).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_ds = test_set.map(normalize).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuInlTqx0Vui"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "  base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "  model = Sequential([\n",
    "      base_model,\n",
    "      GlobalAveragePooling2D(),\n",
    "      Dense(128, activation='relu'),\n",
    "      Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer='adam',\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "      jit_compile=True\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgKbHyXF0xSx",
    "outputId": "f42d5083-592a-44c1-8b05-f02f0ef26150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 84s 112ms/step - loss: 1.0304 - accuracy: 0.6589 - val_loss: 3.0911 - val_accuracy: 0.1935\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.6396 - accuracy: 0.7851 - val_loss: 0.7767 - val_accuracy: 0.7446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7cd3ac1fb850>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEblkrzO02ND",
    "outputId": "c8919b1d-a77d-4c37-92ad-1eea1e70e129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 10s 26ms/step - loss: 0.5658 - accuracy: 0.8106\n",
      "Train set accuracy: 81.1%%\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7420 - accuracy: 0.7510\n",
      "Test set accuracy: 75.1%%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set accuracy: {100.0 * model.evaluate(train_ds)[-1]:0.1f}%%\")\n",
    "print(f\"Test set accuracy: {100.0 * model.evaluate(test_ds)[-1]:0.1f}%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4V_CIB6pWK0",
    "outputId": "3b2dec33-55d4-4ddf-a5f8-bd66d562090f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0s6xCqGpQDm",
    "outputId": "6396a92f-e777-471a-d439-35d35f5e316d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(X_train[0:1, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpCqaHQfEf10",
    "outputId": "aeb604e6-6f80-4cb7-8329-da4788a5203d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3501E6tEtna"
   },
   "outputs": [],
   "source": [
    "#model.save('/content/gdrive/res_net.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7KnW47F1vxR"
   },
   "source": [
    "## Unlearning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0QoQAT01uv7",
    "outputId": "f6e5c0a0-f353-43b4-a4ce-728347125511"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 352)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forget_set, retain_set = keras.utils.split_dataset(train_ds.unbatch(), left_size=0.1)\n",
    "forget_ds = forget_set.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "retain_ds = retain_set.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "int(forget_ds.cardinality()), int(retain_ds.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nvs1Vu8n1vSC"
   },
   "outputs": [],
   "source": [
    "def unlearning(net, retain, forget, validation):\n",
    "\n",
    "  def custom_cross_entropy_loss(class_weights=None):\n",
    "    def loss(y_true, y_pred):\n",
    "      ce_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "      if class_weights is not None:\n",
    "        weights = tf.gather(class_weights, tf.cast(y_true, dtype=tf.int32))\n",
    "        ce_loss = tf.reduce_mean(ce_loss * weights)\n",
    "      return ce_loss\n",
    "    return loss\n",
    "\n",
    "  def add_noise_to_weights(layer, std=0.6):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D) and 'conv' in layer.name:\n",
    "      weights = layer.get_weights()\n",
    "      weights_with_noise = [w + np.random.normal(0, std, w.shape) for w in weights]\n",
    "      layer.set_weights(weights_with_noise)\n",
    "\n",
    "  def vision_confuser(model, std=0.6):\n",
    "    for layer in model.layers:\n",
    "      add_noise_to_weights(layer, std)\n",
    "\n",
    "  epochs = 5\n",
    "  w = 0.5\n",
    "  class_weights = [1, w, w, w, w, w, w, w, w, w]\n",
    "\n",
    "  loss = custom_cross_entropy_loss(class_weights)\n",
    "  metric = metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "  optim = optimizers.SGD(momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "  net.compile(\n",
    "      optimizer=optim,\n",
    "      loss=loss,\n",
    "      metrics=metric,\n",
    "  )\n",
    "\n",
    "  vision_confuser(net, std=0.6)\n",
    "\n",
    "  print(net.summary())\n",
    "\n",
    "  net.fit(retain,verbose=1, epochs=epochs)\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpWnPHSf6dYF",
    "outputId": "10c8adef-de35-46c7-f82e-ced1ff5b4f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, None, None, 2048   23587712  \n",
      "                             )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 2048)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23851274 (90.99 MB)\n",
      "Trainable params: 23798154 (90.78 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "352/352 [==============================] - 40s 55ms/step - loss: 0.1885 - accuracy: 0.8846\n",
      "Epoch 2/5\n",
      "352/352 [==============================] - 19s 53ms/step - loss: 0.1176 - accuracy: 0.9295\n",
      "Epoch 3/5\n",
      "352/352 [==============================] - 18s 50ms/step - loss: 0.0706 - accuracy: 0.9608\n",
      "Epoch 4/5\n",
      "352/352 [==============================] - 18s 50ms/step - loss: 0.0413 - accuracy: 0.9785\n",
      "Epoch 5/5\n",
      "352/352 [==============================] - 18s 51ms/step - loss: 0.0301 - accuracy: 0.9837\n"
     ]
    }
   ],
   "source": [
    "model_ft = unlearning(model, retain_ds, forget_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVbMWaqB6o4d",
    "outputId": "564042e7-2dba-426a-cfe6-1ebaf0b9bc03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step - loss: 0.2258 - accuracy: 0.9228\n",
      "Retain set accuracy: 92.3%%\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6835 - accuracy: 0.8005\n",
      "Test set accuracy: 80.0%%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retain set accuracy: {100.0 * model_ft.evaluate(retain_ds)[-1]:0.1f}%%\")\n",
    "print(f\"Test set accuracy: {100.0 * model_ft.evaluate(test_ds)[-1]:0.1f}%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obTrpmol7BlY",
    "outputId": "442f13f0-42b2-4340-e8a1-a56824dd69f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 17ms/step - loss: 0.3539 - accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35386016964912415, 0.8586000204086304]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(forget_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmNFVJolrg5-",
    "outputId": "f7aaaabc-dc91-4d29-c434-8d081a81f3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 5s 15ms/step - loss: 0.0511 - accuracy: 0.9692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05112976208329201, 0.9691555500030518]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(retain_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGuEGc82rpoj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
